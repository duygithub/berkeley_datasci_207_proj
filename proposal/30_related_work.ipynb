{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c55f5c-7066-4741-b9f2-d4972784859f",
   "metadata": {},
   "source": [
    "Related Work\n",
    "\n",
    "[@Trinh2024] used a similar peer-to-peer lending data and compared nine different models to evaluate consumer credit risk, such as Logistic Regression, Artificial Neural Network, and Gradient Boosting Decision Tree. They concluded that the Gradient Boosting Decision Tree is the best model for most of the evaluation metrics when predicting default risk.\n",
    "\n",
    "[@Change2015] used Lending Club data and fit Logistic Regression, SVM, and Naive Bayes. They concluded that Naive Bayes with Gaussian performs the best at predicting default rate. Furthermore, by applying the best-performing model, the investment return could grow by 50%. \n",
    "\n",
    "[@Souadda2025] evaluated Hyperparameter Optimization methods among Grid Search, Random Search, Hyperopt, and Optuna, across various models. They concluded that LightGBM and XGBoost perform the best. Bayesian methods (Hyperopt, Optuna) achieved comparable accuracy to Grid Search while reducing runtime by up to 75.7-fold. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
