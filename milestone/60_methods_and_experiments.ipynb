{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc1c7a8",
   "metadata": {},
   "source": [
    "Target: \n",
    "Predict expected loan proportions to be paid back, or the expected recovery ratio of the loans.\n",
    "where expected loan recover ratio is the ratio total payment LendingClub (LC) can receive from borrowers to the original total loan amount LC issued. \n",
    "It is calculated as loan_recovery_ratio = total_pymnt / loanAmnt, both variables are present in the data.\n",
    "\n",
    "Method: \n",
    "1. Baseline\n",
    "Linear regression with a few features important from EDA process, for example: loanAmnt, interest rate (int_rate), and one‑hot encoded grade/sub_grade.\n",
    "\n",
    "2. Improved model (1)\n",
    "Regularised linear model (Ridge and/or Lasso) with the full set of engineered features:\n",
    "categorical variables (sub_grade, term, home_ownership, purpose) encoded via target or one‑hot encoding;\n",
    "borrower characteristics (emp_length, annual_inc, dti, open_acc, revol_util, fico_range_low/high);\n",
    "loan characteristics (installment, issue_d year/month, loan_status indicator).\n",
    "Add polynomial or interaction terms if justified (e.g. int_rate × fico).\n",
    "\n",
    "This enhanced linear model penalises over‑fitting, can handle many correlated predictors.\n",
    "\n",
    "3. Improved model (2)\n",
    "Ensemble methods such as Random Forest. \n",
    "Handles nonlinear effects well, and shows good predictability in many applications.\n",
    "\n",
    "4. Improved model (3)\n",
    "Enhanced tree models such as XGBoost and LightGBM.\n",
    "Povides enhanced model capacity in handling nonlinear effects, and delivers very good results in many real-world applications.\n",
    "\n",
    "5. Improved model (4)\n",
    "It can be worthwhile to test out a feed-forward neural network if results are still not satisfactory, with caveat that this model can be overfitting and unnecessarily complex. This model needs hyperparameter tuning and regularization.\n",
    "\n",
    "Gather results and compare. If model results are still not satisfactory, we will try to look at features and perform some feature engineering. Parameter tuning can be another option to boost performance.\n",
    "\n",
    "Result:\n",
    "Expected paid-back portion = Predicted Recovery Ratio from our model\n",
    "\n",
    "Experimental design:\n",
    "1. Data preparation\n",
    "\n",
    "Remove loans with loan_status “current” or “in grace period” (censored); use only fully charged‑off/fully paid data unless modeling censoring explicitly.\n",
    "Split the dataset chronologically into train (70 %) / validation (15 %) / test (15 %) to mimic origination forecasting and avoid look‑ahead bias. Chronologically split also prevents data leakage. \n",
    "Use k‑fold cross‑validation within training for hyperparameter tuning, currently start with 5 folds.\n",
    "Standardise/scale numeric features for linear models, which is important for linear models to derive appropriate weights. Tree models can be insensitive to scales and no need to particularly scale.\n",
    "\n",
    "2. Hyperparameter tuning\n",
    "\n",
    "Linear models: grid search/random search over penalty strength ( \\alpha ), elastic‑net ratio if used.\n",
    "Tree based models: tune learning rate, number of trees, max depth, subsample ratio, colsample_bytree, L1/L2 regularisation.\n",
    "Neural Network models: number of layers, activation function, learning rate, batch size, drop out rate, number of epoches\n",
    "\n",
    "Early stopping is worth considering to avoid overfitting.\n",
    "\n",
    "3. Validation & metrics\n",
    "Mean Absolute Error (MAE), Root Mean Squared Error (RMSE): These are classic ML evaluation metrics to compare predicted value with ground truth. Compare these metrics and see which one achieves the least error.\n",
    "\n",
    "R^2 for linear models to examine the proportion of variance explained. The higher R^2 is, the better explainability and forecast capacity the model captures.\n",
    "\n",
    "4. Caveat\n",
    "We can only use features at funding to avoid data leakage. Features such as last_pymnt_amnt, recoveries, already hinted recovery and default, that can introduce data leakage.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
